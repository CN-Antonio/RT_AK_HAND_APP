{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_MIN_CPP_LEVEL_LOG\"] = \"2\"\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()　\n",
    "# hello = tf.constant('hello,tensorflow')\n",
    "# sess= tf.compat.v1.Session()\n",
    "# print(sess.run(hello))\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "# b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "# c = tf.matmul(a, b)\n",
    "# sess= tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../Dataset/hand/Dataset/'\n",
    "CATEGORIES = ['0', '1','2','3','4','5','6','7','8','9','10']\n",
    "# CATEGORIES = ['A', 'B']\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,category) \n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=C 1=O\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "              \n",
    "    return training_data\n",
    "\n",
    "training_data = create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"data numbers: {len(training_data)}\")\n",
    "random.shuffle(training_data)\n",
    "for sample in training_data[:5]:\n",
    "    print(sample[1], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "X = X/255.0\n",
    "\n",
    "Y = np.array(Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up image augmentation\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=15,\n",
    "#     horizontal_flip=True,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1\n",
    "#     #zoom_range=0.3\n",
    "#     )\n",
    "# datagen.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=11, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=100, validation_split=0.1)\n",
    "# model.fit_generator(datagen.flow(X, Y, batch_size=32),\n",
    "#                     epochs=100,\n",
    "#                     verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/md20220707_hand_11cat.h5')\n",
    "# model = tf.keras.models.load_model(\"../Models/md20220707_hand_2cat.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# quantize int\n",
    "def representative_data_gen():\n",
    "  for input_value in X[:100]:\n",
    "    input_value = np.expand_dims(input_value, axis=0)\n",
    "    input_value = input_value.astype(np.float32)\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"../Models/md20220707_hand_11cat.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "tflite_file = Path(\"../Models/md20220707_hand_11cat.tflite\")\n",
    "tflite_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个测试样本数据\n",
    "test_path = \"../Dataset/hand/Dataset/4/IMG_1183.JPG\"\n",
    "image = cv2.imread(test_path)\n",
    "image = cv2.resize(image, (64, 64))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_bn = image.astype(\"float32\") / 255.0\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image_bn = np.expand_dims(image_bn, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 恢复 keras 模型，并预测\n",
    "keras_file = '../Models/md20220707_hand_11cat.h5'\n",
    "model = tf.keras.models.load_model(keras_file)\n",
    "# model.summary()\n",
    "# tf.autograph.set_verbosity(0)\n",
    "\n",
    "start_time = time.time()\n",
    "pred = model.predict(image_bn)\n",
    "stop_time = time.time()\n",
    "\n",
    "print(f\"prediction: {pred}\")\n",
    "print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))\n",
    "print(\"model size: {:.2f} MB\".format(os.path.getsize(keras_file)/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model_small.png', show_layer_names=False, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自制量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\ProgramData\\Anaconda3\\envs\\0704\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From d:\\ProgramData\\Anaconda3\\envs\\0704\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\dongy\\AppData\\Local\\Temp\\tmpx4u_0l3c\\assets\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Project\\Github\\FireNet-LightWeight-Network-for-Fire-Detection\\Codes\\Train.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=13'>14</a>\u001b[0m converter\u001b[39m.\u001b[39minference_input_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39muint8\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=14'>15</a>\u001b[0m converter\u001b[39m.\u001b[39minference_output_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39muint8\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=16'>17</a>\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mconvert()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=17'>18</a>\u001b[0m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../Models/md20220707_hand_11cat.tflite\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mwrite(tflite_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=19'>20</a>\u001b[0m tflite_file \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m../Models/md20220707_hand_11cat.tflite\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\0704\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:830\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m grappler_config\u001b[39m.\u001b[39mgraph_options\u001b[39m.\u001b[39mrewrite_options\u001b[39m.\u001b[39moptimizers:\n\u001b[0;32m    823\u001b[0m   graph_def \u001b[39m=\u001b[39m _run_graph_optimizations(\n\u001b[0;32m    824\u001b[0m       graph_def,\n\u001b[0;32m    825\u001b[0m       input_tensors,\n\u001b[0;32m    826\u001b[0m       output_tensors,\n\u001b[0;32m    827\u001b[0m       config\u001b[39m=\u001b[39mgrappler_config,\n\u001b[0;32m    828\u001b[0m       graph\u001b[39m=\u001b[39mfrozen_func\u001b[39m.\u001b[39mgraph)\n\u001b[1;32m--> 830\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TFLiteKerasModelConverterV2,\n\u001b[0;32m    831\u001b[0m              \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mconvert(graph_def, input_tensors, output_tensors)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\0704\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:638\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m    635\u001b[0m calibrate_and_quantize, flags \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mquantizer_flags(\n\u001b[0;32m    636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference_input_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference_output_type)\n\u001b[0;32m    637\u001b[0m \u001b[39mif\u001b[39;00m calibrate_and_quantize:\n\u001b[1;32m--> 638\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calibrate_quantize_model(result, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mflags)\n\u001b[0;32m    640\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_sparsify_model:\n\u001b[0;32m    641\u001b[0m   result \u001b[39m=\u001b[39m _mlir_sparsify(result)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\0704\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:450\u001b[0m, in \u001b[0;36mTFLiteConverterBase._calibrate_quantize_model\u001b[1;34m(self, result, inference_input_type, inference_output_type, activations_type, allow_float)\u001b[0m\n\u001b[0;32m    448\u001b[0m   \u001b[39mreturn\u001b[39;00m _mlir_quantize(calibrated)\n\u001b[0;32m    449\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m   \u001b[39mreturn\u001b[39;00m calibrate_quantize\u001b[39m.\u001b[39;49mcalibrate_and_quantize(\n\u001b[0;32m    451\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentative_dataset\u001b[39m.\u001b[39;49minput_gen, inference_input_type,\n\u001b[0;32m    452\u001b[0m       inference_output_type, allow_float, activations_type)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\0704\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py:87\u001b[0m, in \u001b[0;36mCalibrator.calibrate_and_quantize\u001b[1;34m(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\"\"\"Calibrates the model with specified generator and then quantizes it.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[39mThe input shapes of the calibrator are resized with the calibration data if\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m    from the input.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     86\u001b[0m initialized \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m dataset_gen():\n\u001b[0;32m     88\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[0;32m     89\u001b[0m     initialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32md:\\Project\\Github\\FireNet-LightWeight-Network-for-Fire-Detection\\Codes\\Train.ipynb Cell 18'\u001b[0m in \u001b[0;36mrepresentative_data_gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepresentative_data_gen\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=2'>3</a>\u001b[0m   \u001b[39mfor\u001b[39;00m input_value \u001b[39min\u001b[39;00m X[:\u001b[39m100\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=3'>4</a>\u001b[0m     input_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(input_value, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/Github/FireNet-LightWeight-Network-for-Fire-Detection/Codes/Train.ipynb#ch0000016?line=4'>5</a>\u001b[0m     input_value \u001b[39m=\u001b[39m input_value\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# quantize int\n",
    "def representative_data_gen():\n",
    "  for input_value in X[:100]:\n",
    "    input_value = np.expand_dims(input_value, axis=0)\n",
    "    input_value = input_value.astype(np.float32)\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"../Models/md20220707_hand_11cat.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "tflite_file = Path(\"../Models/md20220707_hand_11cat.tflite\")\n",
    "tflite_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflite 模型推理\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "interpreter.set_tensor(input_details['index'], image_bn)\n",
    "\n",
    "start_time = time.time()\n",
    "interpreter.invoke()\n",
    "stop_time = time.time()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details['index'])\n",
    "print(f\"prediction: {output_data}\")\n",
    "print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))\n",
    "print(\"model size: {:.2f} MB\".format(os.path.getsize(tflite_file)/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize int\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in X[:100]:\n",
    "    input_value = np.expand_dims(input_value, axis=0)\n",
    "    input_value = input_value.astype(np.float32)\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_file = Path(\"../Models/Tflites/fire_int.tflite\")\n",
    "tflite_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflite 模型推理\n",
    "tflite_file = Path(\"../Models/Tflites/fire_int.tflite\")\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "interpreter.set_tensor(input_details['index'], image)\n",
    "\n",
    "start_time = time.time()\n",
    "interpreter.invoke()\n",
    "stop_time = time.time()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details['index'])\n",
    "print(f\"prediction: {output_data}\")\n",
    "print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))\n",
    "print(\"model size: {:.2f} MB\".format(os.path.getsize(tflite_file)/1024/1024))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('0704')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "00b32ee9d5435f7e8c0ea93e9f9b183e7e257c6e87205ec845240a130f26f7de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
